(window.webpackJsonp=window.webpackJsonp||[]).push([[104],{746:function(e,s,a){"use strict";a.r(s);var r=a(4),t=Object(r.a)({},(function(){var e=this,s=e._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[s("h2",{attrs:{id:"databricks-foire-aux-questions"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#databricks-foire-aux-questions","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Databricks Foire aux questions")]),e._v(" "),s("h3",{attrs:{id:"quels-sont-les-langages-de-programmation-supportes-par-databricks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#quels-sont-les-langages-de-programmation-supportes-par-databricks","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Quels sont les langages de programmation supportés par Databricks ?")]),e._v(" "),s("p",[e._v("Les langages suivants sont pris en charge : Spark SQL, Java, Scala, Python, R et SQL standard. Cela vous offre la possibilité de sélectionner le langage avec lequel vos développeurs sont à l'aise pour votre projet. De plus, Databricks offre la possibilité aux développeurs d'utiliser plusieurs langages dans un seul carnet de notes.")]),e._v(" "),s("h3",{attrs:{id:"mon-equipe-utilise-actuellement-python-r-pour-l-analyse-des-donnees-est-il-facile-de-passer-a-l-utilisation-de-python-pour-spark-pyspark-et-de-r-pour-spark-sparkr"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mon-equipe-utilise-actuellement-python-r-pour-l-analyse-des-donnees-est-il-facile-de-passer-a-l-utilisation-de-python-pour-spark-pyspark-et-de-r-pour-spark-sparkr","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Mon équipe utilise actuellement Python/R pour l'analyse des données. Est-il facile de passer à l'utilisation de Python pour Spark (PySpark) et de R pour Spark (SparkR) ?")]),e._v(" "),s("p",[e._v("La syntaxe et les méthodologies utilisées par PySpark et SparkR sont axées sur l'idée de plusieurs ordinateurs exécutant le code que vous avez écrit, de sorte que leur syntaxe diffère dans une certaine mesure de celle de Python et de R. Par conséquent, il peut être nécessaire de suivre une formation pour acquérir les compétences nécessaires à l'utilisation de la version Spark des langages. D'une manière générale, la transition vers l'utilisation de PySpark et SparkR n'est pas très compliquée.")]),e._v(" "),s("h3",{attrs:{id:"mon-projet-de-donnees-n-est-pas-complexe-et-ne-necessite-pas-l-utilisation-de-spark-ou-de-la-puissance-de-calcul-parallele-puis-je-quand-meme-utiliser-les-databricks-pour-ce-projet"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mon-projet-de-donnees-n-est-pas-complexe-et-ne-necessite-pas-l-utilisation-de-spark-ou-de-la-puissance-de-calcul-parallele-puis-je-quand-meme-utiliser-les-databricks-pour-ce-projet","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Mon projet de données n'est pas complexe et ne nécessite pas l'utilisation de Spark ou de la puissance de calcul parallèle, puis-je quand même utiliser les Databricks pour ce projet ?")]),e._v(" "),s("p",[e._v("Absolument, oui. Databricks permet d'écrire votre code en utilisant le langage Python ou R ordinaire et d'utiliser pandas et d'autres bibliothèques populaires. Il permet également d'exécuter votre code sur une seule machine virtuelle (un seul cluster), avec un minimum de ressources informatiques requises pour votre projet.")]),e._v(" "),s("h3",{attrs:{id:"comment-puis-je-telecharger-mon-propre-jeu-de-donnees-et-l-utiliser-dans-databricks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#comment-puis-je-telecharger-mon-propre-jeu-de-donnees-et-l-utiliser-dans-databricks","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Comment puis-je télécharger mon propre jeu de données et l'utiliser dans Databricks ?")]),e._v(" "),s("p",[e._v("Vous pouvez télécharger et gérer votre ensemble de données en utilisant le portail DHSF. Les données téléchargées seront stockées dans le nuage à l'aide d'Azure Blog Storage. Pour accéder au fichier téléchargé de manière programmatique en utilisant Databricks, vous devrez obtenir le chemin d'accès où le fichier est stocké. Le chemin de votre fichier téléchargé peut être obtenu en allant sur le portail et en allant sur ........... Voici un exemple de code qui montre comment accéder à des données stockées dans Blob Storage en utilisant python dans Databricks :")]),e._v(" "),s("h4",{attrs:{id:"puis-je-creer-mon-propre-cluster-dans-databricks"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#puis-je-creer-mon-propre-cluster-dans-databricks","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Puis-je créer mon propre Cluster dans Databricks ?")]),e._v(" "),s("p",[e._v("Non. Pour l'instant, les clusters nécessaires à votre projet seront créés et configurés par l'équipe DHSF en fonction de vos besoins. Vous disposerez des commandes pour démarrer et arrêter les clusters.")]),e._v(" "),s("h3",{attrs:{id:"l-environnement-databricks-est-il-certifie-pour-traiter-des-informations-protege-b"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#l-environnement-databricks-est-il-certifie-pour-traiter-des-informations-protege-b","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" L'environnement Databricks est-il certifié pour traiter des informations Protégé B ?")]),e._v(" "),s("p",[e._v("Non, actuellement, l'environnement Databricks soutenu par le DataHub scientifique fédéral ne supporte que les données UNCLASSIFIED.")]),e._v(" "),s("h3",{attrs:{id:"puis-je-acceder-a-l-environnement-databricks-a-l-aide-d-un-carnet-jupyter-fonctionnant-localement-ou-d-ide-tels-que-pycharm-vs-code-et-spyder"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#puis-je-acceder-a-l-environnement-databricks-a-l-aide-d-un-carnet-jupyter-fonctionnant-localement-ou-d-ide-tels-que-pycharm-vs-code-et-spyder","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Puis-je accéder à l'environnement Databricks à l'aide d'un carnet Jupyter fonctionnant localement ou d'IDE tels que PyCharm, VS Code et Spyder ?")]),e._v(" "),s("p",[e._v("Oui, vous pouvez le faire. Cependant, cela nécessite une certaine configuration sur les Databricks. Veuillez nous contacter avec vos besoins et nous serons heureux de vous aider.")]),e._v(" "),s("h3",{attrs:{id:"comment-mes-donnees-et-le-code-source-sont-ils-proteges-contre-les-acces-non-autorises"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#comment-mes-donnees-et-le-code-source-sont-ils-proteges-contre-les-acces-non-autorises","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Comment mes données et le code source sont-ils protégés contre les accès non autorisés ?")]),e._v(" "),s("p",[e._v("Les environnements DHSF Analytics suivent le principe de sécurité du \"moindre privilège\", ce qui signifie que seul l'ensemble minimal de privilèges requis pour effectuer les tâches sera accordé aux utilisateurs. Des contrôles d'accès et des procédures seront mis en place pour garantir que tout code source créé dans votre projet Databricks ne peut être consulté et exécuté que par les utilisateurs autorisés à le faire. De même, les données stockées dans le compte Azure Blog Storage de votre projet seront gérées à l'aide d'un contrôle d'accès au niveau des dossiers afin de garantir que seuls les utilisateurs ayant reçu une autorisation explicite pourront lire et écrire dans les fichiers et les dossiers.")]),e._v(" "),s("h4",{attrs:{id:"qui-sera-responsable-de-la-configuration-des-ressources-databricks-dossiers-clusters-groupes-d-acces-et-utilisateurs-du-compte-de-stockage-blob-et-des-controles-d-acces-relatifs-a-ces-composants"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#qui-sera-responsable-de-la-configuration-des-ressources-databricks-dossiers-clusters-groupes-d-acces-et-utilisateurs-du-compte-de-stockage-blob-et-des-controles-d-acces-relatifs-a-ces-composants","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" Qui sera responsable de la configuration des ressources Databricks (dossiers, clusters, groupes d'accès et utilisateurs), du compte de stockage Blob et des contrôles d'accès relatifs à ces composants ?")]),e._v(" "),s("p",[e._v("La configuration des ressources Databricks et du compte de stockage sera gérée par l'équipe DHSF.")]),e._v(" "),s("h3",{attrs:{id:"j-ai-un-projet-d-ia-apprentissage-machine-que-je-voudrais-mettre-en-œuvre-a-l-aide-de-databricks-comment-puis-je-commencer"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#j-ai-un-projet-d-ia-apprentissage-machine-que-je-voudrais-mettre-en-œuvre-a-l-aide-de-databricks-comment-puis-je-commencer","aria-hidden":"true",tabindex:"-1"}},[e._v("#")]),e._v(" J'ai un projet d'IA/apprentissage machine que je voudrais mettre en œuvre à l'aide de Databricks, comment puis-je commencer ?")]),e._v(" "),s("p",[e._v("Pour le moment, nous n'assumerons pas la responsabilité de la construction des modèles ML, mais nous serons heureux de vous aider en vous fournissant les outils et services techniques nécessaires pour atteindre l'objectif de votre projet.")])])}),[],!1,null,null,null);s.default=t.exports}}]);